{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Set Up the Lab Environment\n",
    "\n",
    "This introductory lab guides the attendees with the following activities:\n",
    "\n",
    "1. Setting up the AI Project in the AI Foundry\n",
    "2. Deploying an LLM and embedding models\n",
    "3. Establish connectivity from VS Code to the AI Project\n",
    "4. Perform a simple Chat completion call to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Test your lab environment\n",
    "\n",
    "To test that your lab was setup successfully, run the below code that sends a message to the deployed model, asking it to tell a joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True) # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the project connection string and model from environment variables, which are needed to make a call to the LLM\n",
    "project_connection_string = os.getenv(\"AIPROJECT_CONNECTION_STRING\")\n",
    "model = os.getenv(\"CHAT_MODEL\")\n",
    "api_key = os.getenv(\"CHAT_MODEL_API_KEY\")\n",
    "\n",
    "# Verify variables\n",
    "if not project_connection_string or not model:\n",
    "    raise ValueError(\"Missing required environment variables. Check AIPROJECT_CONNECTION_STRING and CHAT_MODEL in .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the connection string to connect to your Foundry project\n",
    "try:\n",
    "    project = AIProjectClient.from_connection_string(\n",
    "        conn_str=project_connection_string, credential=DefaultAzureCredential()\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to project: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_lKz9CKOEZIEBm2v2bWOotyyf\n"
     ]
    }
   ],
   "source": [
    "## need to login using the command azd auth login\n",
    "agent = project.agents.create_agent(\n",
    "        model=\"gpt-4o\",\n",
    "        name=\"Agent123\",\n",
    "        instructions=\"You are helpful AI assistant. Answer the user's questions.\",\n",
    "     \n",
    "    )\n",
    "print(f\"Created agent, agent ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, thread ID: thread_VecAiDfqZ6RaVmn6l0R7llTO\n"
     ]
    }
   ],
   "source": [
    "    # Create a thread\n",
    "thread = project.agents.create_thread()\n",
    "print(f\"Created thread, thread ID: {thread.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, ID: msg_YVLFDY1ufu2GCFBTEp1vMP5g\n"
     ]
    }
   ],
   "source": [
    "    # Get messages from the thread\n",
    "message = project.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"Hey, can you tell a joke about teddy bear?\",\n",
    "    )\n",
    "print(f\"Created message, ID: {message.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished with status: RunStatus.COMPLETED\n"
     ]
    }
   ],
   "source": [
    "run = project.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id)\n",
    "    # [END create_and_process_run]\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID: msg_xnLj6mvbSELrXuCD8t91Oxl9\n",
      "Role: MessageRole.AGENT\n",
      "Content:\n",
      "Sure! Why did the teddy bear say no to dessert?  \n",
      "\n",
      "Because it was already stuffed!\n",
      "--------------------------------------------------\n",
      "Message ID: msg_YVLFDY1ufu2GCFBTEp1vMP5g\n",
      "Role: MessageRole.USER\n",
      "Content:\n",
      "Hey, can you tell a joke about teddy bear?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Deleted agent'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = project.agents.list_messages(thread_id=thread.id)\n",
    "\n",
    "for msg in messages.data:\n",
    "    print(f\"Message ID: {msg.id}\")\n",
    "    print(f\"Role: {msg.role}\")\n",
    "    print(\"Content:\")\n",
    "    for content in msg.content:\n",
    "        if content['type'] == 'text':\n",
    "            print(content['text']['value'])\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Delete the agent once done\n",
    "project.agents.delete_agent(agent.id)\n",
    "(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm project connectivity to Azure OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5,280 feet in a mile.\n"
     ]
    }
   ],
   "source": [
    "aoai_client = project.inference.get_azure_openai_client(api_version=\"2024-06-01\")\n",
    "\n",
    "response = aoai_client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # Model deployment name\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How many feet are in a mile?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
